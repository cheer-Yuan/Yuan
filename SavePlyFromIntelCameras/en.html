<!DOCTYPE HTML>
<!--
	Prologue by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<head>
  <title>Prologue by HTML5 UP</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <link rel="stylesheet" href="../assets/css/main.css" />
  <link href="../prism.css" rel="stylesheet" />
</head>
<body class="is-preload, line-numbers">
<script src="../prism.js"></script>


<!-- Header -->
<div id="header">

  <div class="top">

    <!-- Logo -->
    <div id="logo">
      <span class="image avatar48"><img src="images/avatar.jpg" alt="" /></span>
      <h1 id="title">Zhiyuan LIU</h1>
      <p>Golang / C / C++ Developer</p>
    </div>

    <!-- Nav -->
    <nav id="nav">
      <ul>
        <li><a href="#top" id="top-link"><span class="icon solid fa-home">Intro</span></a></li>
        <li><a href="#portfolio" id="portfolio-link"><span class="icon solid fa-th">Portfolio</span></a></li>
        <li><a href="#about" id="about-link"><span class="icon solid fa-user">About Me</span></a></li>
        <li><a href="#contact" id="contact-link"><span class="icon solid fa-envelope">Contact</span></a></li>
      </ul>
    </nav>

  </div>

  <div class="bottom">

    <!-- Social Icons -->
    <ul class="icons">
      <li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
      <li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
      <li><a href=https://github.com/cheer-Yuan class="icon brands fa-github"><span class="label">Github</span></a></li>
      <li><a href="#" class="icon brands fa-dribbble"><span class="label">Dribbble</span></a></li>
      <li><a href="#" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
    </ul>

  </div>

</div>

<!-- Main -->
<div id="main">

  <!-- Intro -->
  <section id="top" class="one dark cover">
    <div class="container">

      <header>
        <h2 class="alt">Use Intel Realsense2 SDK to record consecutively and autonomously .ply point cloud information from a L515 LiDAR or a D455 depth camera.</h2>
        <p>Prerequisites : Basic knowledge in cMake, C++, point clouds and Realsense2 API</p>
      </header>


    </div>
  </section>

  <!-- General -->
  <section id="General" class="two">
    <div class="container">

      <header>
        <h2>I. General description</h2>
      </header>

      <p style=text-align:justify;>This work consists of recording the cloud point information generated by a Intel depth device. A program in C++ is produced using the Intel Realsense2 SDK.</p >
      <p style=text-align:justify;>Since the target is to save as more information as possible, on a Raspberry device whose processor has a lower performance. In order to maximize the speed of recording, the original SDK is adopted to make it possible to save the .ply files without texture information.</p >



    </div>
  </section>

  <!-- started -->
  <section id="started" class="three">
    <div class="container">

      <header>
        <h2>II. Get started</h2>
      </header>

      <header>
        <h3 style=text-align:justify>1. Intel Realsense2 SDK</h3>
      </header>

      <p style=text-align:justify;>Download : <a href="https://github.com/cheer-Yuan/librealsense">https://github.com/cheer-Yuan/librealsense</a></p >
      <p style=text-align:justify;><strong>If never installed the Intel Realsense2 SDK</strong> : compile and install the Intel Realsense2 SDK according to <a href="https://dev.intelrealsense.com/docs/installation">https://dev.intelrealsense.com/docs/installation</a></p >
      <p style=text-align:justify;><strong>If an SDK is already installed</strong> : re-install using the following commands (for linux, add flags for multicore compilation) </p >
<pre>
<code class="language-bash">mkdir build && cd build
cmake ../ -DCMAKE_BUILD_TYPE=Release
sudo make uninstall && make clean && make && sudo make install</code>
</pre>


    </div>
  </section>

  <!-- Detailed -->
  <section id="Detailed" class="four">
    <div class="container">

      <header>
        <h2>III. Details of the project</h2>
      </header>

      <header>
        <h3 style=text-align:justify>1. Control the sampling resolution</h3>
      </header>

      <p style=text-align:justify>If the usage does not require a resolution of 640*480 or higher for the cloud points but a faster recording speed, we can consider of lowering the resolution of the data pipe, since the minimal resolution only need to process about 1/4 of the original data.</p>
      <p style=text-align:justify>The lowest resolution supported varies according to different camera models. This value is 320*240 for L515 and 424*240 for D455. </p>

<pre>
<code class="language-cpp">rs2::pipeline pipe;
rs2::config cfg;
if (config.if_lowres() == 0) {
    cfg.enable_stream(RS2_STREAM_DEPTH, 640, 480, RS2_FORMAT_ANY, 0);
} else if (config.if_lowres() == 5) {
    cfg.enable_stream(RS2_STREAM_DEPTH, 424, 240, RS2_FORMAT_ANY, 0);
} else {
    cfg.enable_stream(RS2_STREAM_DEPTH, 320, 240, RS2_FORMAT_ANY, 0);
}
if (config.if_rgb() == 1) {
    cfg.enable_stream(RS2_STREAM_COLOR, 0, 0, RS2_FORMAT_ANY, 0);
}
if (config.if_infrarouge() == 1) {
    cfg.enable_stream(RS2_STREAM_INFRARED, 0, 0, RS2_FORMAT_ANY, 0);
}
pipe.start(cfg);</code>
</pre>

      <p style=text-align:justify></p>

      <header>
        <h3 style=text-align:justify>2. Save the file for each frame transferred by the data pipe</h3>
      </header>

      <p style=text-align:justify>A kernel function is implemented, which takes the data pipe as one of its parameters. Operations related to colors will be ignored to save the time if the data information is nor required by the parameter entered by the user. </p>

<pre>
<code class="language-cpp">void saveKernel(const rs2::colorizer& color_map, const rs2::pipeline& pipe, int ifPly, int ifDepth, int ifImages, int ifInfr, int ifColor, const std::string& direction){
    std::string currenttime = GetLocalTimeWithMs();

    // Wait until a new set of frames become available
    rs2::frameset frames = pipe.wait_for_frames();

    // write the point cloud to disk
    if (ifPly) {
        // Get the first depth and color frame
        auto depth = frames.get_depth_frame();
        auto color = frames.get_color_frame();

        rs2::pointcloud pc;

        // Generate the name of the file
        std::stringstream ply_file;
        ply_file << direction << currenttime << "Points.ply";

        if (ifColor == 1) {
            // Map the point cloud to the given color frame
            pc.map_to(color);

            // Generate the point cloud
            rs2::points points = pc.calculate(depth);
            // Export the point cloud to a PLY file with colors
            points.export_to_ply(ply_file.str(), color);
        } else if (ifColor == 0) {
            // Generate the point cloud
            rs2::points points = pc.calculate(depth);
            // Export the point cloud to a PLY file without colors
            points.export_to_ply_notexture(ply_file.str());
        } else if (ifColor == -1) {
            // Generate the point cloud
            rs2::points points = pc.calculate(depth);
            // Export the point cloud to a PLY file with the pipe mode
            points.export_to_ply_notexture(ply_file.str());
        }

        std::cout << "Saved " << ply_file.str() << std::endl;
    }

    // write images to disk
    for (auto&& frame : frames)
    {
        // we can only save video frames as pngs, so we skip the rest
        if (auto vf = frame.as&lt;rs2::video_frame>())
        {
            // use the colorizer to get an rgb image for the depth stream
            if (vf.is&lt;rs2::depth_frame>()) vf = color_map.process(frame);

            // write the corresponding the images to disk, according to the given parameters
            std::stringstream png_file;

            if (vf.get_profile().stream_name() == "Depth") {
                if (ifDepth) {
                    png_file << direction << currenttime << vf.get_profile().stream_name() << ".png";
                    stbi_write_png(png_file.str().c_str(), vf.get_width(), vf.get_height(), vf.get_bytes_per_pixel(), vf.get_data(), vf.get_stride_in_bytes());
                    std::cout << "Saved " << png_file.str() << std::endl;

                    // record the metadata
                    std::stringstream csv_file;
                    csv_file << direction << currenttime << vf.get_profile().stream_name()
                             << "-metadata.csv";
                    metadataToCsv(vf, csv_file.str());
                }
            }

            if (vf.get_profile().stream_name() == "Infrared") {
                if (ifInfr) {
                    png_file << direction << currenttime << vf.get_profile().stream_name() << ".png";
                    stbi_write_png(png_file.str().c_str(), vf.get_width(), vf.get_height(), vf.get_bytes_per_pixel(), vf.get_data(), vf.get_stride_in_bytes());
                    std::cout << "Saved " << png_file.str() << std::endl;

                    // record the metadata
                    std::stringstream csv_file;
                    csv_file << direction << currenttime << vf.get_profile().stream_name()
                             << "-metadata.csv";
                    metadataToCsv(vf, csv_file.str());
                }
            }

            if (vf.get_profile().stream_name() == "Color") {
                if (ifImages) {
                    png_file << direction << currenttime << vf.get_profile().stream_name() << ".png";
                    stbi_write_png(png_file.str().c_str(), vf.get_width(), vf.get_height(), vf.get_bytes_per_pixel(), vf.get_data(), vf.get_stride_in_bytes());
                    std::cout << "Saved " << png_file.str() << std::endl;

                    // record the metadata
                    std::stringstream csv_file;
                    csv_file << direction << currenttime << vf.get_profile().stream_name()
                             << "-metadata.csv";
                    metadataToCsv(vf, csv_file.str());
                }
            }
        }
    }
}</code>
</pre>

      <p style=text-align:justify></p>


      <header>
        <h3 style=text-align:justify>3. Work without the texture information</h3>
      </header>

      <p style=text-align:justify>The original Realsense2 API exports the point cloud file with the texture information in the form of RGB values. It can be removed if is not necessary for the usage, in order to achieve a higher speed of record. For this reason, the Realsense2 library is modified and another function which exports smaller .ply files is created alongside. </p>

<pre>
<code class="language-cpp">void points::export_to_ply_notexture(const std::string& fname) {
    auto stream_profile = get_stream().get();
    auto video_stream_profile = dynamic_cast&lt;video_stream_profile_interface*>(stream_profile);
    if (!video_stream_profile)
        throw librealsense::invalid_value_exception("stream must be video stream");
    const auto vertices = get_vertices();
    std::vector&lt;float3> new_vertices;
    std::map&lt;int, int> index2reducedIndex;

    new_vertices.reserve(get_vertex_count());
    assert(get_vertex_count());
    for (int i = 0; i < get_vertex_count(); ++i)
        if (fabs(vertices[i].x) >= MIN_DISTANCE || fabs(vertices[i].y) >= MIN_DISTANCE ||
            fabs(vertices[i].z) >= MIN_DISTANCE)
        {
            index2reducedIndex[i] = (int)new_vertices.size();
            new_vertices.push_back({ vertices[i].x,  -1*vertices[i].y, -1*vertices[i].z });
        }

    const auto threshold = 0.05f;
    auto width = video_stream_profile->get_width();
    std::vector&lt;std::tuple&lt;int, int, int>> faces;
    for( uint32_t x = 0; x < width - 1; ++x )
    {
        for( uint32_t y = 0; y < video_stream_profile->get_height() - 1; ++y )
        {
            auto a = y * width + x, b = y * width + x + 1, c = (y + 1)*width + x, d = (y + 1)*width + x + 1;
            if (vertices[a].z && vertices[b].z && vertices[c].z && vertices[d].z
                && abs(vertices[a].z - vertices[b].z) < threshold && abs(vertices[a].z - vertices[c].z) < threshold
                && abs(vertices[b].z - vertices[d].z) < threshold && abs(vertices[c].z - vertices[d].z) < threshold)
            {
                if (index2reducedIndex.count(a) == 0 || index2reducedIndex.count(b) == 0 || index2reducedIndex.count(c) == 0 ||
                    index2reducedIndex.count(d) == 0)
                    continue;

                faces.emplace_back(index2reducedIndex[a], index2reducedIndex[d], index2reducedIndex[b]);
                faces.emplace_back(index2reducedIndex[d], index2reducedIndex[a], index2reducedIndex[c]);
            }
        }
    }

    std::ofstream out(fname);
    out << "ply\n";
    out << "format binary_little_endian 1.0\n";
    out << "comment pointcloud saved from Realsense Viewer\n";
    out << "element vertex " << new_vertices.size() << "\n";
    out << "property float" << sizeof(float) * 8 << " x\n";
    out << "property float" << sizeof(float) * 8 << " y\n";
    out << "property float" << sizeof(float) * 8 << " z\n";
    out << "element face " << faces.size() << "\n";
    out << "property list uchar int vertex_indices\n";
    out << "end_header\n";
    out.close();

    out.open(fname, std::ios_base::app | std::ios_base::binary);
    for (int i = 0; i < new_vertices.size(); ++i)
    {
        // we assume little endian architecture on your device
        out.write(reinterpret_cast&lt;const char*>(&(new_vertices[i].x)), sizeof(float));
        out.write(reinterpret_cast&lt;const char*>(&(new_vertices[i].y)), sizeof(float));
        out.write(reinterpret_cast&lt;const char*>(&(new_vertices[i].z)), sizeof(float));
    }
    auto size = faces.size();
    for (int i = 0; i < size; ++i) {
        int three = 3;
        out.write(reinterpret_cast&lt;const char*>(&three), sizeof(uint8_t));
        out.write(reinterpret_cast&lt;const char*>(&(std::get<0>(faces[i]))), sizeof(int));
        out.write(reinterpret_cast&lt;const char*>(&(std::get<1>(faces[i]))), sizeof(int));
        out.write(reinterpret_cast&lt;const char*>(&(std::get<2>(faces[i]))), sizeof(int));
    }
}</code>
</pre>

    </div>
  </section>

</div>

<!-- Benchmarks -->
<section id="Benchmarks" class="five">
  <div class="container">

    <header>
      <h2>IV. Benchmarks</h2>
    </header>

    <header>
      <h3 style=text-align:justify>1. Intel Realsense2 SDK</h3>
    </header>

    <p style=text-align:justify;>Download : <a href="https://github.com/cheer-Yuan/librealsense">https://github.com/cheer-Yuan/librealsense</a></p >
    <p style=text-align:justify;><strong>If never installed the Intel Realsense2 SDK</strong> : compile and install the Intel Realsense2 SDK according to <a href="https://dev.intelrealsense.com/docs/installation">https://dev.intelrealsense.com/docs/installation</a></p >
    <p style=text-align:justify;><strong>If an SDK is already installed</strong> : re-install using the following commands (for linux, add flags for multicore compilation) </p >
    <pre>
<code class="language-bash">mkdir build && cd build
cmake ../ -DCMAKE_BUILD_TYPE=Release
sudo make uninstall && make clean && make && sudo make install</code>
</pre>


  </div>
</section>

<!-- Footer -->
<div id="footer">

  <!-- Copyright -->
  <ul class="copyright">
    <li>&copy; Zhiyuan LIU. All rights reserved.</li>
  </ul>

</div>

<!-- Scripts -->
<script src="../assets/js/jquery.min.js"></script>
<script src="../assets/js/jquery.scrolly.min.js"></script>
<script src="../assets/js/jquery.scrollex.min.js"></script>
<script src="../assets/js/browser.min.js"></script>
<script src="../assets/js/breakpoints.min.js"></script>
<script src="../assets/js/util.js"></script>
<script src="../assets/js/main.js"></script>

</body>
</html>